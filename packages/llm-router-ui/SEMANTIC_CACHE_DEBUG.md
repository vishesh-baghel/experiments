# Semantic Cache Debugging

## What I Added

### Detailed Logging
Added comprehensive logging to understand cache behavior:

```typescript
// When generating embeddings
console.log(`[Cache] Generating embedding for: "${text}..."`);
console.log(`[Cache] âœ“ Embedding generated (256 dimensions)`);

// When looking up cache
console.log(`[Cache] Query: "${query}..."`);
console.log(`[Cache] Best match: "${cachedQuery}..." (similarity: 92.3%)`);
console.log(`[Cache] Threshold: 85.0%`);
console.log(`[Cache] âœ“ HIT - Returning cached response`);
// or
console.log(`[Cache] âœ— MISS - Similarity below threshold`);
```

---

## What You'll See Now

### Test 1: Exact Match
```bash
# First request
Query: "hi"
[Cache] Generating embedding for: "hi"
[Cache] âœ“ Embedding generated (256 dimensions)
[Cache] âœ— MISS - No cached entries yet
â†’ Calls LLM
â†’ Caches response

# Second request (exact same)
Query: "hi"
[Cache] Query: "hi"
[Cache] Best match: "hi" (similarity: 100.0%)
[Cache] Threshold: 85.0%
[Cache] âœ“ HIT - Returning cached response
â†’ Returns instantly!
```

### Test 2: Semantic Match
```bash
# First request
Query: "what can you do?"
[Cache] âœ— MISS
â†’ Calls LLM
â†’ Caches response

# Second request (semantically similar)
Query: "how can you help me?"
[Cache] Query: "how can you help me?"
[Cache] Best match: "what can you do?" (similarity: 91.2%)
[Cache] Threshold: 85.0%
[Cache] âœ“ HIT - Returning cached response
â†’ Returns cached! âœ…
```

### Test 3: No Match
```bash
Query: "I've been charged twice..."
[Cache] Query: "I've been charged twice..."
[Cache] Best match: "hi" (similarity: 12.3%)
[Cache] Threshold: 85.0%
[Cache] âœ— MISS - Similarity below threshold
â†’ Calls LLM (correct behavior)
```

---

## Possible Issues & Solutions

### Issue 1: Embeddings Failing
**Symptom:**
```
[Cache] âœ— Failed to generate embedding: API key not found
[Cache] Best match: "hi" (similarity: 0.0%)
```

**Cause:** OpenAI API key missing or invalid

**Solution:**
```bash
# Check .env file
cat .env | grep OPENAI_API_KEY

# Should see:
OPENAI_API_KEY=sk-...
```

---

### Issue 2: All Similarities Are 0%
**Symptom:**
```
[Cache] Best match: "hi" (similarity: 0.0%)
[Cache] Best match: "hello" (similarity: 0.0%)
```

**Cause:** Embeddings are failing, returning zero vectors

**Solution:** Check console for embedding errors, verify API key

---

### Issue 3: Threshold Too High
**Symptom:**
```
[Cache] Best match: "how can you help?" (similarity: 82.5%)
[Cache] Threshold: 85.0%
[Cache] âœ— MISS - Similarity below threshold
```

**Cause:** Queries are similar but below 85% threshold

**Solution:** Lower threshold in agent initialization:
```typescript
const agent = new CustomerCareAgent(undefined, {
  cacheOptions: {
    similarityThreshold: 0.80, // Lower from 0.85
  },
});
```

---

## Expected Similarity Scores

### High Similarity (Should Cache)
```
"hi" â†’ "hello"                           â†’ 95-98%
"what can you do?" â†’ "how can you help?" â†’ 88-92%
"business hours" â†’ "when are you open?"  â†’ 90-94%
```

### Medium Similarity (Borderline)
```
"hi" â†’ "good morning"                    â†’ 75-82%
"help me" â†’ "I need assistance"          â†’ 80-85%
```

### Low Similarity (Should NOT Cache)
```
"hi" â†’ "I've been charged twice"         â†’ 5-15%
"hours" â†’ "refund policy"                â†’ 10-20%
```

---

## Testing Semantic Cache

### Test Sequence

**1. Simple greeting variations:**
```
Send: "hi"           â†’ MISS (first time)
Send: "hello"        â†’ HIT (95%+ similarity) âœ…
Send: "hey there"    â†’ HIT (90%+ similarity) âœ…
```

**2. Help queries:**
```
Send: "what can you do?"     â†’ MISS
Send: "how can you help me?" â†’ HIT (88%+ similarity) âœ…
Send: "what services?"       â†’ HIT (85%+ similarity) âœ…
```

**3. Different topics:**
```
Send: "business hours"       â†’ MISS
Send: "refund policy"        â†’ MISS (different topic)
Send: "when are you open?"   â†’ HIT (matches "business hours") âœ…
```

---

## Console Output Example

```bash
# Start server
pnpm dev

# First "hi"
[Cache] Generating embedding for: "hi"
[Cache] âœ“ Embedding generated (256 dimensions)
[Cache] âœ— MISS - No cached entries yet
Routing: { cacheHit: false, cached: true }

# Send "hello" (similar)
[Cache] Generating embedding for: "hello"
[Cache] âœ“ Embedding generated (256 dimensions)
[Cache] Query: "hello"
[Cache] Best match: "hi" (similarity: 96.8%)
[Cache] Threshold: 85.0%
[Cache] âœ“ HIT - Returning cached response
â†’ No routing log (cache hit before routing!)

# Send "what can you do?"
[Cache] Generating embedding for: "what can you do?"
[Cache] âœ“ Embedding generated (256 dimensions)
[Cache] Query: "what can you do?"
[Cache] Best match: "hi" (similarity: 18.2%)
[Cache] Threshold: 85.0%
[Cache] âœ— MISS - Similarity below threshold
Routing: { cacheHit: false, cached: true }

# Send "how can you help me?" (similar to above)
[Cache] Generating embedding for: "how can you help me?"
[Cache] âœ“ Embedding generated (256 dimensions)
[Cache] Query: "how can you help me?"
[Cache] Best match: "what can you do?" (similarity: 91.3%)
[Cache] Threshold: 85.0%
[Cache] âœ“ HIT - Returning cached response
â†’ Semantic match! âœ…
```

---

## Troubleshooting

### If semantic matching isn't working:

1. **Check embedding generation:**
   - Look for `[Cache] âœ“ Embedding generated`
   - If you see errors, check API key

2. **Check similarity scores:**
   - Should be 85%+ for similar queries
   - If always 0%, embeddings are failing

3. **Check threshold:**
   - Default is 85%
   - Lower to 80% if needed

4. **Check API key:**
   ```bash
   echo $OPENAI_API_KEY
   # Should output: sk-...
   ```

---

## Summary

**What to expect:**
- âœ… Exact matches: 100% similarity â†’ Cache hit
- âœ… Semantic matches: 85%+ similarity â†’ Cache hit
- âœ… Different topics: <85% similarity â†’ Cache miss

**Console logs will show:**
- Embedding generation status
- Similarity scores for each query
- Cache hit/miss decisions
- Why decisions were made

**Test it now and watch the console!** ðŸ”
